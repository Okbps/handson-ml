{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.datasets import load_iris, make_classification\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data[:, (2, 3)]\n",
    "y = (iris.target == 0).astype(np.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=0.0001, class_weight=None, eta0=1.0, fit_intercept=True,\n",
       "      max_iter=None, n_iter=None, n_jobs=1, penalty=None, random_state=42,\n",
       "      shuffle=True, tol=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_clf = Perceptron(random_state=42)\n",
    "per_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = per_clf.predict([[2, 0.5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNN (MLP) High Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_10, y_10 = make_classification(n_samples=1000, n_classes=10, n_features=4, n_informative=4, n_redundant=0, n_repeated=0, n_clusters_per_class=1, random_state=42)\n",
    "X_10 = X_10.astype(np.float32)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_10, y_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_10.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = tf.contrib.learn.infer_real_valued_columns_from_input(X_train)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "feature_cols = tf.estimator.infer_real_valued_columns_from_input(X_train)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dnn_clf = tf.estimator.DNNClassifier(hidden_units=[300, 100], n_classes=10, feature_columns=feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\POKROV~1\\AppData\\Local\\Temp\\tmp4ak2r_zn\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000000001AD9B668>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_device_fn': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': 'C:\\\\Users\\\\POKROV~1\\\\AppData\\\\Local\\\\Temp\\\\tmp4ak2r_zn'}\n"
     ]
    }
   ],
   "source": [
    "dnn_clf = tf.contrib.learn.DNNClassifier(hidden_units=[300, 100], n_classes=10, feature_columns=feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\POKROV~1\\AppData\\Local\\Temp\\tmp4ak2r_zn\\model.ckpt-400\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 400 into C:\\Users\\POKROV~1\\AppData\\Local\\Temp\\tmp4ak2r_zn\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.5987427, step = 401\n",
      "INFO:tensorflow:global_step/sec: 763.36\n",
      "INFO:tensorflow:loss = 0.4615118, step = 501 (0.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 999.999\n",
      "INFO:tensorflow:loss = 0.34938648, step = 601 (0.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 806.453\n",
      "INFO:tensorflow:loss = 0.5087976, step = 701 (0.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 1075.26\n",
      "INFO:tensorflow:loss = 0.55055463, step = 801 (0.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 813.01\n",
      "INFO:tensorflow:loss = 0.46410385, step = 901 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 961.538\n",
      "INFO:tensorflow:loss = 0.39882973, step = 1001 (0.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 884.955\n",
      "INFO:tensorflow:loss = 0.40361607, step = 1101 (0.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 934.581\n",
      "INFO:tensorflow:loss = 0.29607952, step = 1201 (0.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 980.392\n",
      "INFO:tensorflow:loss = 0.3222566, step = 1301 (0.092 sec)\n",
      "INFO:tensorflow:global_step/sec: 990.098\n",
      "INFO:tensorflow:loss = 0.5649348, step = 1401 (0.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 854.702\n",
      "INFO:tensorflow:loss = 0.43160847, step = 1501 (0.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 934.578\n",
      "INFO:tensorflow:loss = 0.19020821, step = 1601 (0.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 961.54\n",
      "INFO:tensorflow:loss = 0.23944904, step = 1701 (0.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 934.578\n",
      "INFO:tensorflow:loss = 0.3143517, step = 1801 (0.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 892.857\n",
      "INFO:tensorflow:loss = 0.30063638, step = 1901 (0.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 892.857\n",
      "INFO:tensorflow:loss = 0.26742283, step = 2001 (0.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 806.451\n",
      "INFO:tensorflow:loss = 0.33512333, step = 2101 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 970.874\n",
      "INFO:tensorflow:loss = 0.26655495, step = 2201 (0.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 900.902\n",
      "INFO:tensorflow:loss = 0.3337313, step = 2301 (0.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 763.357\n",
      "INFO:tensorflow:loss = 0.19838805, step = 2401 (0.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 884.956\n",
      "INFO:tensorflow:loss = 0.1907666, step = 2501 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 943.397\n",
      "INFO:tensorflow:loss = 0.2192144, step = 2601 (0.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.672\n",
      "INFO:tensorflow:loss = 0.16494104, step = 2701 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 900.9\n",
      "INFO:tensorflow:loss = 0.2786806, step = 2801 (0.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.334\n",
      "INFO:tensorflow:loss = 0.24527834, step = 2901 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 970.872\n",
      "INFO:tensorflow:loss = 0.101159036, step = 3001 (0.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 909.092\n",
      "INFO:tensorflow:loss = 0.13889843, step = 3101 (0.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 934.578\n",
      "INFO:tensorflow:loss = 0.21750183, step = 3201 (0.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 862.069\n",
      "INFO:tensorflow:loss = 0.1264528, step = 3301 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 769.23\n",
      "INFO:tensorflow:loss = 0.14841092, step = 3401 (0.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 909.092\n",
      "INFO:tensorflow:loss = 0.14043349, step = 3501 (0.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 909.09\n",
      "INFO:tensorflow:loss = 0.07969935, step = 3601 (0.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.334\n",
      "INFO:tensorflow:loss = 0.2286558, step = 3701 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 877.194\n",
      "INFO:tensorflow:loss = 0.20401655, step = 3801 (0.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 862.068\n",
      "INFO:tensorflow:loss = 0.08656903, step = 3901 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 961.54\n",
      "INFO:tensorflow:loss = 0.12178132, step = 4001 (0.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 970.872\n",
      "INFO:tensorflow:loss = 0.21221125, step = 4101 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.334\n",
      "INFO:tensorflow:loss = 0.11086197, step = 4201 (0.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 787.401\n",
      "INFO:tensorflow:loss = 0.15414907, step = 4301 (0.127 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4400 into C:\\Users\\POKROV~1\\AppData\\Local\\Temp\\tmp4ak2r_zn\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.098535635.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SKCompat()"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_clf_sk = tf.contrib.learn.SKCompat(dnn_clf)\n",
    "dnn_clf_sk.fit(X_train, y_train, batch_size=50, steps=4000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNN (MLP) Low Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 28*28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10\n",
    "learning_rate = 0.01\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, (None, n_inputs), \"X\")\n",
    "y = tf.placeholder(tf.int32, (None), \"y\")\n",
    "\n",
    "def neuron_layer(X, n_neurons, name, activation=None):\n",
    "    with tf.name_scope(name):\n",
    "        n_inputs = int(X.get_shape()[1])\n",
    "        stddev = 2 / np.sqrt(n_inputs)\n",
    "        init = tf.truncated_normal((n_inputs, n_neurons), stddev=stddev)\n",
    "        W = tf.Variable(init, name=\"kernel\")\n",
    "        b = tf.Variable(tf.zeros([n_neurons]), name=\"bias\")\n",
    "        Z = tf.matmul(X, W) + b\n",
    "        if activation is not None:\n",
    "            return activation(Z)\n",
    "        else:\n",
    "            return Z\n",
    "        \n",
    "with tf.name_scope(\"dnn\"):\n",
    "#     hidden1 = neuron_layer(X, n_hidden1, name=\"hidden1\", activation=tf.nn.relu)\n",
    "#     hidden2 = neuron_layer(hidden1, n_hidden2, name=\"hidden2\", activation=tf.nn.relu)\n",
    "#     logits = neuron_layer(hidden2, n_outputs, name=\"outputs\")\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, name=\"hidden1\", activation=tf.nn.relu)\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, name=\"hidden2\", activation=tf.nn.relu)\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")\n",
    "    \n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "    \n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "    \n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float16))\n",
    "    acc_summary = tf.summary.scalar('accuracy', accuracy)\n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train = X_train.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "X_test = X_test.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "y_train = y_train.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)\n",
    "X_valid = X_train[:5000]\n",
    "y_valid = y_train[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_batch(X, y, batch_size):\n",
    "    rnd_idx = np.random.permutation(len(X))\n",
    "    n_batches = len(X) // batch_size\n",
    "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
    "        X_batch, y_batch = X[batch_idx], y[batch_idx]\n",
    "        yield (X_batch, y_batch)\n",
    "        \n",
    "def get_logdir():\n",
    "    now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "    root_logdir = \"tf_logs\"\n",
    "    return \"{}/run-{}/\".format(root_logdir, now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Accuracy Train: 0.94 Test 0.2048\n",
      "1 Accuracy Train: 0.94 Test 0.2048\n",
      "2 Accuracy Train: 0.94 Test 0.2048\n",
      "3 Accuracy Train: 0.88 Test 0.2048\n",
      "4 Accuracy Train: 0.98 Test 0.2048\n",
      "5 Accuracy Train: 0.9 Test 0.2048\n",
      "6 Accuracy Train: 0.98 Test 0.2048\n",
      "7 Accuracy Train: 0.94 Test 0.2048\n",
      "8 Accuracy Train: 1.0 Test 0.2048\n",
      "9 Accuracy Train: 1.0 Test 0.2048\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 50\n",
    "\n",
    "checkpoint_path = \"/tmp/mnist_model.ckpt\"\n",
    "checkpoint_epoch_path = checkpoint_path + \".epoch\"\n",
    "final_model_path = \"tmp/mnist_model_final.ckpt\"\n",
    "\n",
    "file_writer = tf.summary.FileWriter(get_logdir(), tf.get_default_graph())\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    if os.path.isfile(checkpoint_epoch_path):\n",
    "        with open(checkpoint_epoch_path, \"rb\") as f:\n",
    "            start_epoch = int(f.read())\n",
    "        print(\"Training was interrupted. Continuing at epoch\", start_epoch)\n",
    "        saver.restore(sess, checkpoint_path)\n",
    "    else:\n",
    "        start_epoch = 0\n",
    "        sess.run(init)\n",
    "    \n",
    "    for epoch in range(start_epoch, n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        \n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        \n",
    "        acc_test, summary_str = sess.run([accuracy, acc_summary], feed_dict={X: X_test, y: y_test})\n",
    "        \n",
    "        file_writer.add_summary(summary_str, epoch)\n",
    "        save_path = saver.save(sess, checkpoint_path)\n",
    "        \n",
    "        with open(checkpoint_epoch_path, \"wb\") as f:\n",
    "            f.write(b\"%d\" % (epoch + 1))\n",
    "        \n",
    "        print(epoch, \"Accuracy Train:\", acc_train, \"Test\", acc_test)\n",
    "        \n",
    "    save_path = saver.save(sess, final_model_path)\n",
    "    file_writer.close()\n",
    "    os.remove(checkpoint_epoch_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from tmp/mnist_model_final.ckpt\n",
      "[5 0 4 1 9 2 1 3 1 4]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, final_model_path)\n",
    "    Z = logits.eval(feed_dict={X: X_valid[:10]})\n",
    "    y_pred = np.argmax(Z, axis=1)\n",
    "    print(y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
