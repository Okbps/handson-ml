{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.ensemble as ensemble\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.datasets import load_iris, make_moons, make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_regression(n_samples=1000, n_features=10)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_clf = LogisticRegression()\n",
    "rnd_clf = ensemble.RandomForestClassifier()\n",
    "svm_clf = SVC()\n",
    "\n",
    "voting_clf = ensemble.VotingClassifier(\n",
    "    estimators=[\n",
    "        ('lr', log_clf),\n",
    "        ('rf', rnd_clf),\n",
    "        ('svc', svm_clf)\n",
    "    ],\n",
    "    voting='hard'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_clf = ensemble.BaggingClassifier(\n",
    "    DecisionTreeClassifier(), n_estimators=500, max_samples=100, bootstrap=True, n_jobs=-1, oob_score=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal length (cm) 0.11282333911948725\n",
      "sepal width (cm) 0.02531533273520786\n",
      "petal length (cm) 0.4348743204666668\n",
      "petal width (cm) 0.4269870076786382\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "rnd_clf = ensemble.RandomForestClassifier(n_estimators=500, n_jobs=-1)\n",
    "rnd_clf.fit(iris[\"data\"], iris[\"target\"])\n",
    "for name, score in zip(iris[\"feature_names\"], rnd_clf.feature_importances_):\n",
    "    print(name, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_clf = ensemble.AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=1), n_estimators=200, algorithm=\"SAMME.R\", learning_rate=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=2, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_reg1 = DecisionTreeRegressor(max_depth=2)\n",
    "tree_reg1.fit(X, y)\n",
    "\n",
    "y2 = y - tree_reg1.predict(X)\n",
    "tree_reg2 = DecisionTreeRegressor(max_depth=2)\n",
    "tree_reg2.fit(X, y2)\n",
    "\n",
    "y3 = y - tree_reg2.predict(X)\n",
    "tree_reg3 = DecisionTreeRegressor(max_depth=2)\n",
    "tree_reg3.fit(X, y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = sum(tree.predict([X[0]]) for tree in (tree_reg1, tree_reg2, tree_reg3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=1.0, loss='ls', max_depth=2, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=3, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbrt = ensemble.GradientBoostingRegressor(max_depth=2, n_estimators=3, learning_rate=1.0)\n",
    "gbrt.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=2, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=120, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbrt = ensemble.GradientBoostingRegressor(max_depth=2, n_estimators=120)\n",
    "gbrt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = [mean_squared_error(y_test, y_pred) for y_pred in gbrt.staged_predict(X_test)]\n",
    "bst_n_estimators = np.argmin(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=2, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=119, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbrt_best = ensemble.GradientBoostingRegressor(max_depth=2, n_estimators=bst_n_estimators)\n",
    "gbrt_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbrt = ensemble.GradientBoostingRegressor(max_depth=2, warm_start=True)\n",
    "\n",
    "min_test_error = float('inf')\n",
    "error_going_up = 0\n",
    "for n_estimators in range(1, 120):\n",
    "    gbrt.n_estimators = n_estimators\n",
    "    gbrt.fit(X_train, y_train)\n",
    "    y_pred = gbrt.predict(X_test)\n",
    "    test_error = mean_squared_error(y_test, y_pred)\n",
    "    if test_error < min_test_error:\n",
    "        min_val_error = test_error\n",
    "        error_going_up = 0\n",
    "    else:\n",
    "        error_going_up += 1\n",
    "        if error_going_up == 5:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Load the MNIST data (introduced in Chapter 3), and split it into a training set, a\n",
    "validation set, and a test set (e.g., use 40,000 instances for training, 10,000 for\n",
    "validation, and 10,000 for testing). Then train various classifiers, such as a Random\n",
    "Forest classifier, an Extra-Trees classifier, and an SVM. Next, try to combine them\n",
    "into an ensemble that outperforms them all on the validation set, using a soft or hard\n",
    "voting classifier. Once you have found one, try it on the test setLoad the MNIST data (introduced in Chapter 3), and split it into a training set, a\n",
    "validation set, and a test set (e.g., use 40,000 instances for training, 10,000 for\n",
    "validation, and 10,000 for testing). Then train various classifiers, such as a Random\n",
    "Forest classifier, an Extra-Trees classifier, and an SVM. Next, try to combine them\n",
    "into an ensemble that outperforms them all on the validation set, using a soft or hard\n",
    "voting classifier. Once you have found one, try it on the test set. How much better\n",
    "does it perform compared to the individual classifiers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DESCR': 'mldata.org dataset: mnist-original',\n",
       " 'COL_NAMES': ['label', 'data'],\n",
       " 'target': array([0., 0., 0., ..., 9., 9., 9.]),\n",
       " 'data': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = fetch_mldata('MNIST original')\n",
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784) (70000,)\n"
     ]
    }
   ],
   "source": [
    "print(mnist['data'].shape, mnist['target'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triple_split(X, y, ind1, ind2, ind3):\n",
    "    shuffled_indices = np.random.permutation(len(X))\n",
    "    \n",
    "    X_train, y_train = X[shuffled_indices][:ind1],      y[shuffled_indices][:ind1]\n",
    "    X_test,  y_test  = X[shuffled_indices][ind1:ind2], y[shuffled_indices][ind1:ind2]\n",
    "    X_val,   y_val   = X[shuffled_indices][ind2:ind3], y[shuffled_indices][ind2:ind3]\n",
    "\n",
    "    return X_train, X_test, X_val, y_train, y_test, y_val\n",
    "  \n",
    "X_train, X_test, X_val, y_train, y_test, y_val = triple_split(mnist['data'], mnist['target'], 1600, 2000, 2400)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm: 0.915000\n",
      "rf: 0.820000\n",
      "et: 0.847500\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(kernel='linear', probability=True)\n",
    "rf = ensemble.RandomForestClassifier()\n",
    "et = ensemble.ExtraTreesClassifier()\n",
    "\n",
    "svm.fit(X_train, y_train)\n",
    "rf.fit(X_train, y_train)\n",
    "et.fit(X_train, y_train)\n",
    "\n",
    "print(\"svm: %f\" % accuracy_score(y_test, svm.predict(X_test)))\n",
    "print(\"rf: %f\" % accuracy_score(y_test, rf.predict(X_test)))\n",
    "print(\"et: %f\" % accuracy_score(y_test, et.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm+rf+et hard: 0.897500\n",
      "svm+rf+et soft: 0.935000\n"
     ]
    }
   ],
   "source": [
    "voting_clf = ensemble.VotingClassifier(\n",
    "    estimators=[\n",
    "#         ('svm', LinearSVC()),\n",
    "#         ('rf', ensemble.RandomForestClassifier()),\n",
    "#         ('et', ensemble.ExtraTreesClassifier())\n",
    "        ('svm', svm),\n",
    "        ('rf', rf),\n",
    "        ('et', et)\n",
    "    ],\n",
    "    voting='hard')\n",
    "\n",
    "voting_clf.fit(X_train, y_train)\n",
    "print(\"svm+rf+et hard: %f\" % accuracy_score(y_test, voting_clf.predict(X_test)))\n",
    "\n",
    "voting_clf.voting='soft'\n",
    "voting_clf.fit(X_train, y_train)\n",
    "print(\"svm+rf+et soft: %f\" % accuracy_score(y_test, voting_clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm: 0.887500\n",
      "rf: 0.830000\n",
      "et: 0.867500\n",
      "svm+rf+et soft: 0.910000\n"
     ]
    }
   ],
   "source": [
    "print(\"svm: %f\" % accuracy_score(y_val, svm.predict(X_val)))\n",
    "print(\"rf: %f\" % accuracy_score(y_val, rf.predict(X_val)))\n",
    "print(\"et: %f\" % accuracy_score(y_val, et.predict(X_val)))\n",
    "print(\"svm+rf+et soft: %f\" % accuracy_score(y_val, voting_clf.predict(X_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the individual classifiers from the previous exercise to make predictions on the\n",
    "validation set, and create a new training set with the resulting predictions: each\n",
    "training instance is a vector containing the set of predictions from all your classifiers\n",
    "for an image, and the target is the image’s class. Congratulations, you have just\n",
    "trained a blender, and together with the classifiers they form a stacking ensemble!\n",
    "Now let’s evaluate the ensemble on the test set. For each image in the test set, make\n",
    "predictions with all your classifiers, then feed the predictions to the blender to get the\n",
    "ensemble’s predictions. How does it compare to the voting classifier you trained\n",
    "earlier?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X_test_stack.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "voting_clf.estimators_[0].predict_proba(X_test).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-f4a79ad0a0f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvoting_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mX_test_stack\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_test_stack\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\core\\shape_base.py\u001b[0m in \u001b[0;36mhstack\u001b[1;34m(tup)\u001b[0m\n\u001b[0;32m    284\u001b[0m     \u001b[1;31m# As a special case, dimension 0 of 1-dimensional arrays is \"horizontal\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0marrs\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marrs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 286\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    287\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input arrays must have same number of dimensions"
     ]
    }
   ],
   "source": [
    "# X_test_stack = np.zeros((X_test.shape[0], len(voting_clf.estimators_)))\n",
    "X_test_stack = np.empty((X_test.shape[0],))\n",
    "\n",
    "for e in voting_clf.estimators_:\n",
    "    X_test_stack = np.hstack([X_test_stack, e.predict_proba(X_test)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
