{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from functools import partial\n",
    "from datetime import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanishing/Exploding Gradients\n",
    "Xavier and He initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, (None, 3), name=\"X\")\n",
    "n_hidden1 = 300\n",
    "\n",
    "he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, kernel_initializer=he_init, name=\"Hidden1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "alpha = 1\n",
    "lx = np.linspace(-4, 4, 100)\n",
    "ly = list(map(lambda x: alpha*np.exp(x)-alpha if x<0 else x, lx))\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(10, 4)\n",
    "# ax.xaxis.set_ticks_position('bottom')\n",
    "# ax.yaxis.set_ticks_position('left')\n",
    "\n",
    "ax.set_aspect('equal')\n",
    "ax.grid(True, which='both')\n",
    "\n",
    "# set the x-spine (see below for more info on `set_position`)\n",
    "ax.spines['left'].set_position('zero')\n",
    "\n",
    "# turn off the right spine/ticks\n",
    "ax.spines['right'].set_color('none')\n",
    "ax.yaxis.tick_left()\n",
    "\n",
    "# set the y-spine\n",
    "ax.spines['bottom'].set_position('zero')\n",
    "\n",
    "# turn off the top spine/ticks\n",
    "ax.spines['top'].set_color('none')\n",
    "ax.xaxis.tick_bottom()\n",
    "\n",
    "\n",
    "ax.plot(lx, ly)\n",
    "ax.set_title(\"ELU\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.elu, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train = X_train.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "X_test = X_test.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "y_train = y_train.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)\n",
    "X_valid = X_test[:5000]\n",
    "y_valid = y_test[:5000]\n",
    "\n",
    "n_inputs = 28*28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10\n",
    "n_epochs = 10\n",
    "learning_rate = 0.01\n",
    "batch_size = 50\n",
    "threshold = 1.0\n",
    "n_batches = X_train.shape[0]//batch_size\n",
    "\n",
    "def shuffle_batch(X, y, batch_size):\n",
    "    rnd_idx = np.random.permutation(len(X))\n",
    "    n_batches = len(X) // batch_size\n",
    "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
    "        X_batch, y_batch = X[batch_idx], y[batch_idx]\n",
    "        yield (X_batch, y_batch)\n",
    "        \n",
    "def get_logdir():\n",
    "    now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "    root_logdir = \"tf_logs\"\n",
    "    return \"{}/run-{}/\".format(root_logdir, now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "training = tf.placeholder_with_default(input=False, shape=(), name=\"training\")\n",
    "\n",
    "my_batch_norm_layer = partial(tf.layers.batch_normalization, training=training, momentum=0.9)\n",
    "\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, name=\"hidden1\")\n",
    "bn1 = my_batch_norm_layer(hidden1)\n",
    "bn1_act = tf.nn.elu(bn1)\n",
    "\n",
    "hidden2 = tf.layers.dense(bn1_act, n_hidden2, name=\"hidden2\")\n",
    "bn2 = my_batch_norm_layer(hidden2)\n",
    "bn2_act = tf.nn.elu(bn2)\n",
    "\n",
    "logits_before_bn = tf.layers.dense(bn2_act, n_outputs, name=\"outputs\")\n",
    "logits = my_batch_norm_layer(logits_before_bn)\n",
    "\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "    \n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    grads_vars = optimizer.compute_gradients(loss)\n",
    "    capped_gvs = [(tf.clip_by_value(grad, -threshold, threshold), var) for grad, var in grads_vars]\n",
    "    training_op = optimizer.apply_gradients(capped_gvs)\n",
    "#     training_op = optimizer.minimize(loss)\n",
    "    \n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float16))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()    \n",
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run([training_op, extra_update_ops], feed_dict={training: True, X: X_batch, y: y_batch})\n",
    "            \n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        \n",
    "        print(epoch, \"Test accuracy:\", accuracy_val)\n",
    "        save_path = saver.save(sess, \"tmp/bn_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reusing Pretrained Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "saver = tf.train.import_meta_graph(\"tmp/mnist_model_final.ckpt.meta\")\n",
    "\n",
    "X = tf.get_default_graph().get_tensor_by_name(\"X:0\")\n",
    "y = tf.get_default_graph().get_tensor_by_name(\"y:0\")\n",
    "accuracy = tf.get_default_graph().get_tensor_by_name(\"eval/accuracy:0\")\n",
    "training_op = tf.get_default_graph().get_operation_by_name(\"train/GradientDescent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for op in (X, y, accuracy, training_op):\n",
    "    tf.add_to_collection(\"important_ops\", op)\n",
    "    \n",
    "X, y, accuracy, training_op = tf.get_collection(\"important_ops\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reuse_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=\"hidden[123]\")\n",
    "reuse_vars_dict = dict([(var.op.name, var) for var in reuse_vars])\n",
    "restore_saver = tf.train.Saver(reuse_vars_dict)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"tmp/mnist_model_final.ckpt\")\n",
    "    save_path = saver.save(sess, \"tmp/hidden123_mnist_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Freezing the Lower Layers: fetch selected vars to optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.get_default_graph().get_tensor_by_name(\"loss/loss:0\")\n",
    "\n",
    "train_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"hidden[34]|outputs\")\n",
    "training_op = optimizer.minimize(loss, var_list=train_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Freezing the Lower Layers: add \"stop gradient\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=\"hidden2\")\n",
    "#     hidden2_stop = tf.stop_gradient(hidden2)\n",
    "    hidden3 = tf.layers.dense(hidden2, 50, activation=tf.nn.relu, name=\"hidden3\")\n",
    "    hidden4 = tf.layers.dense(hidden3, 25, activation=tf.nn.relu, name=\"hidden4\")\n",
    "    logits = tf.layers.dense(hidden4, n_outputs, name=\"outputs\")\n",
    "    \n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy)\n",
    "    \n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)    \n",
    "    \n",
    "saver = tf.train.Saver()    \n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.3198201\n",
      "Test loss: 0.24075203\n",
      "Test loss: 0.19596633\n",
      "Test loss: 0.16589253\n",
      "Test loss: 0.1499387\n",
      "Test loss: 0.13555607\n",
      "Test loss: 0.12521482\n",
      "Test loss: 0.121826746\n",
      "Test loss: 0.12452241\n",
      "Test loss: 0.10719646\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X:X_batch, y:y_batch})\n",
    "        \n",
    "        loss_test = sess.run(loss, feed_dict={X:X_test, y:y_test})\n",
    "        print(\"Epoch:\", epoch, \"Test loss:\", loss_test)\n",
    "    \n",
    "    save_path = saver.save(sess, \"tmp/layers_x4_mnist_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caching the Frozen Layers"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# exporting saved graph to tensorboard\n",
    "tf.reset_default_graph()\n",
    "\n",
    "tf.train.import_meta_graph(\"tmp/mnist_model_final.ckpt.meta\")\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    tf.train.write_graph(tf.get_default_graph(), \"tf_logs\", \"restored-mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'X' type=Placeholder>,\n",
       " <tf.Operation 'y' type=Placeholder>,\n",
       " <tf.Operation 'hidden1/kernel/Initializer/random_uniform/shape' type=Const>,\n",
       " <tf.Operation 'hidden1/kernel/Initializer/random_uniform/min' type=Const>,\n",
       " <tf.Operation 'hidden1/kernel/Initializer/random_uniform/max' type=Const>,\n",
       " <tf.Operation 'hidden1/kernel/Initializer/random_uniform/RandomUniform' type=RandomUniform>,\n",
       " <tf.Operation 'hidden1/kernel/Initializer/random_uniform/sub' type=Sub>,\n",
       " <tf.Operation 'hidden1/kernel/Initializer/random_uniform/mul' type=Mul>,\n",
       " <tf.Operation 'hidden1/kernel/Initializer/random_uniform' type=Add>,\n",
       " <tf.Operation 'hidden1/kernel' type=VariableV2>,\n",
       " <tf.Operation 'hidden1/kernel/Assign' type=Assign>,\n",
       " <tf.Operation 'hidden1/kernel/read' type=Identity>,\n",
       " <tf.Operation 'hidden1/bias/Initializer/zeros' type=Const>,\n",
       " <tf.Operation 'hidden1/bias' type=VariableV2>,\n",
       " <tf.Operation 'hidden1/bias/Assign' type=Assign>,\n",
       " <tf.Operation 'hidden1/bias/read' type=Identity>,\n",
       " <tf.Operation 'dnn/hidden1/MatMul' type=MatMul>,\n",
       " <tf.Operation 'dnn/hidden1/BiasAdd' type=BiasAdd>,\n",
       " <tf.Operation 'dnn/hidden1/Relu' type=Relu>,\n",
       " <tf.Operation 'hidden2/kernel/Initializer/random_uniform/shape' type=Const>,\n",
       " <tf.Operation 'hidden2/kernel/Initializer/random_uniform/min' type=Const>,\n",
       " <tf.Operation 'hidden2/kernel/Initializer/random_uniform/max' type=Const>,\n",
       " <tf.Operation 'hidden2/kernel/Initializer/random_uniform/RandomUniform' type=RandomUniform>,\n",
       " <tf.Operation 'hidden2/kernel/Initializer/random_uniform/sub' type=Sub>,\n",
       " <tf.Operation 'hidden2/kernel/Initializer/random_uniform/mul' type=Mul>,\n",
       " <tf.Operation 'hidden2/kernel/Initializer/random_uniform' type=Add>,\n",
       " <tf.Operation 'hidden2/kernel' type=VariableV2>,\n",
       " <tf.Operation 'hidden2/kernel/Assign' type=Assign>,\n",
       " <tf.Operation 'hidden2/kernel/read' type=Identity>,\n",
       " <tf.Operation 'hidden2/bias/Initializer/zeros' type=Const>,\n",
       " <tf.Operation 'hidden2/bias' type=VariableV2>,\n",
       " <tf.Operation 'hidden2/bias/Assign' type=Assign>,\n",
       " <tf.Operation 'hidden2/bias/read' type=Identity>,\n",
       " <tf.Operation 'dnn/hidden2/MatMul' type=MatMul>,\n",
       " <tf.Operation 'dnn/hidden2/BiasAdd' type=BiasAdd>,\n",
       " <tf.Operation 'dnn/hidden2/Relu' type=Relu>,\n",
       " <tf.Operation 'hidden3/kernel/Initializer/random_uniform/shape' type=Const>,\n",
       " <tf.Operation 'hidden3/kernel/Initializer/random_uniform/min' type=Const>,\n",
       " <tf.Operation 'hidden3/kernel/Initializer/random_uniform/max' type=Const>,\n",
       " <tf.Operation 'hidden3/kernel/Initializer/random_uniform/RandomUniform' type=RandomUniform>,\n",
       " <tf.Operation 'hidden3/kernel/Initializer/random_uniform/sub' type=Sub>,\n",
       " <tf.Operation 'hidden3/kernel/Initializer/random_uniform/mul' type=Mul>,\n",
       " <tf.Operation 'hidden3/kernel/Initializer/random_uniform' type=Add>,\n",
       " <tf.Operation 'hidden3/kernel' type=VariableV2>,\n",
       " <tf.Operation 'hidden3/kernel/Assign' type=Assign>,\n",
       " <tf.Operation 'hidden3/kernel/read' type=Identity>,\n",
       " <tf.Operation 'hidden3/bias/Initializer/zeros' type=Const>,\n",
       " <tf.Operation 'hidden3/bias' type=VariableV2>,\n",
       " <tf.Operation 'hidden3/bias/Assign' type=Assign>,\n",
       " <tf.Operation 'hidden3/bias/read' type=Identity>,\n",
       " <tf.Operation 'dnn/hidden3/MatMul' type=MatMul>,\n",
       " <tf.Operation 'dnn/hidden3/BiasAdd' type=BiasAdd>,\n",
       " <tf.Operation 'dnn/hidden3/Relu' type=Relu>,\n",
       " <tf.Operation 'hidden4/kernel/Initializer/random_uniform/shape' type=Const>,\n",
       " <tf.Operation 'hidden4/kernel/Initializer/random_uniform/min' type=Const>,\n",
       " <tf.Operation 'hidden4/kernel/Initializer/random_uniform/max' type=Const>,\n",
       " <tf.Operation 'hidden4/kernel/Initializer/random_uniform/RandomUniform' type=RandomUniform>,\n",
       " <tf.Operation 'hidden4/kernel/Initializer/random_uniform/sub' type=Sub>,\n",
       " <tf.Operation 'hidden4/kernel/Initializer/random_uniform/mul' type=Mul>,\n",
       " <tf.Operation 'hidden4/kernel/Initializer/random_uniform' type=Add>,\n",
       " <tf.Operation 'hidden4/kernel' type=VariableV2>,\n",
       " <tf.Operation 'hidden4/kernel/Assign' type=Assign>,\n",
       " <tf.Operation 'hidden4/kernel/read' type=Identity>,\n",
       " <tf.Operation 'hidden4/bias/Initializer/zeros' type=Const>,\n",
       " <tf.Operation 'hidden4/bias' type=VariableV2>,\n",
       " <tf.Operation 'hidden4/bias/Assign' type=Assign>,\n",
       " <tf.Operation 'hidden4/bias/read' type=Identity>,\n",
       " <tf.Operation 'dnn/hidden4/MatMul' type=MatMul>,\n",
       " <tf.Operation 'dnn/hidden4/BiasAdd' type=BiasAdd>,\n",
       " <tf.Operation 'dnn/hidden4/Relu' type=Relu>,\n",
       " <tf.Operation 'outputs/kernel/Initializer/random_uniform/shape' type=Const>,\n",
       " <tf.Operation 'outputs/kernel/Initializer/random_uniform/min' type=Const>,\n",
       " <tf.Operation 'outputs/kernel/Initializer/random_uniform/max' type=Const>,\n",
       " <tf.Operation 'outputs/kernel/Initializer/random_uniform/RandomUniform' type=RandomUniform>,\n",
       " <tf.Operation 'outputs/kernel/Initializer/random_uniform/sub' type=Sub>,\n",
       " <tf.Operation 'outputs/kernel/Initializer/random_uniform/mul' type=Mul>,\n",
       " <tf.Operation 'outputs/kernel/Initializer/random_uniform' type=Add>,\n",
       " <tf.Operation 'outputs/kernel' type=VariableV2>,\n",
       " <tf.Operation 'outputs/kernel/Assign' type=Assign>,\n",
       " <tf.Operation 'outputs/kernel/read' type=Identity>,\n",
       " <tf.Operation 'outputs/bias/Initializer/zeros' type=Const>,\n",
       " <tf.Operation 'outputs/bias' type=VariableV2>,\n",
       " <tf.Operation 'outputs/bias/Assign' type=Assign>,\n",
       " <tf.Operation 'outputs/bias/read' type=Identity>,\n",
       " <tf.Operation 'dnn/outputs/MatMul' type=MatMul>,\n",
       " <tf.Operation 'dnn/outputs/BiasAdd' type=BiasAdd>,\n",
       " <tf.Operation 'eval/in_top_k/InTopKV2/k' type=Const>,\n",
       " <tf.Operation 'eval/in_top_k/InTopKV2' type=InTopKV2>,\n",
       " <tf.Operation 'eval/Cast' type=Cast>,\n",
       " <tf.Operation 'eval/Const' type=Const>,\n",
       " <tf.Operation 'eval/Mean' type=Mean>,\n",
       " <tf.Operation 'loss/SparseSoftmaxCrossEntropyWithLogits/Shape' type=Shape>,\n",
       " <tf.Operation 'loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' type=SparseSoftmaxCrossEntropyWithLogits>,\n",
       " <tf.Operation 'loss/Const' type=Const>,\n",
       " <tf.Operation 'loss/Mean' type=Mean>,\n",
       " <tf.Operation 'train/gradients/Shape' type=Const>,\n",
       " <tf.Operation 'train/gradients/grad_ys_0' type=Const>,\n",
       " <tf.Operation 'train/gradients/Fill' type=Fill>,\n",
       " <tf.Operation 'train/gradients/loss/Mean_grad/Reshape/shape' type=Const>,\n",
       " <tf.Operation 'train/gradients/loss/Mean_grad/Reshape' type=Reshape>,\n",
       " <tf.Operation 'train/gradients/loss/Mean_grad/Shape' type=Shape>,\n",
       " <tf.Operation 'train/gradients/loss/Mean_grad/Tile' type=Tile>,\n",
       " <tf.Operation 'train/gradients/loss/Mean_grad/Shape_1' type=Shape>,\n",
       " <tf.Operation 'train/gradients/loss/Mean_grad/Shape_2' type=Const>,\n",
       " <tf.Operation 'train/gradients/loss/Mean_grad/Const' type=Const>,\n",
       " <tf.Operation 'train/gradients/loss/Mean_grad/Prod' type=Prod>,\n",
       " <tf.Operation 'train/gradients/loss/Mean_grad/Const_1' type=Const>,\n",
       " <tf.Operation 'train/gradients/loss/Mean_grad/Prod_1' type=Prod>,\n",
       " <tf.Operation 'train/gradients/loss/Mean_grad/Maximum/y' type=Const>,\n",
       " <tf.Operation 'train/gradients/loss/Mean_grad/Maximum' type=Maximum>,\n",
       " <tf.Operation 'train/gradients/loss/Mean_grad/floordiv' type=FloorDiv>,\n",
       " <tf.Operation 'train/gradients/loss/Mean_grad/Cast' type=Cast>,\n",
       " <tf.Operation 'train/gradients/loss/Mean_grad/truediv' type=RealDiv>,\n",
       " <tf.Operation 'train/gradients/zeros_like' type=ZerosLike>,\n",
       " <tf.Operation 'train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/PreventGradient' type=PreventGradient>,\n",
       " <tf.Operation 'train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim' type=Const>,\n",
       " <tf.Operation 'train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims' type=ExpandDims>,\n",
       " <tf.Operation 'train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul' type=Mul>,\n",
       " <tf.Operation 'train/gradients/dnn/outputs/BiasAdd_grad/BiasAddGrad' type=BiasAddGrad>,\n",
       " <tf.Operation 'train/gradients/dnn/outputs/BiasAdd_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'train/gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'train/gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'train/gradients/dnn/outputs/MatMul_grad/MatMul' type=MatMul>,\n",
       " <tf.Operation 'train/gradients/dnn/outputs/MatMul_grad/MatMul_1' type=MatMul>,\n",
       " <tf.Operation 'train/gradients/dnn/outputs/MatMul_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'train/gradients/dnn/outputs/MatMul_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'train/gradients/dnn/outputs/MatMul_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'train/gradients/dnn/hidden4/Relu_grad/ReluGrad' type=ReluGrad>,\n",
       " <tf.Operation 'train/gradients/dnn/hidden4/BiasAdd_grad/BiasAddGrad' type=BiasAddGrad>,\n",
       " <tf.Operation 'train/gradients/dnn/hidden4/BiasAdd_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'train/gradients/dnn/hidden4/BiasAdd_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'train/gradients/dnn/hidden4/BiasAdd_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'train/gradients/dnn/hidden4/MatMul_grad/MatMul' type=MatMul>,\n",
       " <tf.Operation 'train/gradients/dnn/hidden4/MatMul_grad/MatMul_1' type=MatMul>,\n",
       " <tf.Operation 'train/gradients/dnn/hidden4/MatMul_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'train/gradients/dnn/hidden4/MatMul_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'train/gradients/dnn/hidden4/MatMul_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'train/gradients/dnn/hidden3/Relu_grad/ReluGrad' type=ReluGrad>,\n",
       " <tf.Operation 'train/gradients/dnn/hidden3/BiasAdd_grad/BiasAddGrad' type=BiasAddGrad>,\n",
       " <tf.Operation 'train/gradients/dnn/hidden3/BiasAdd_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'train/gradients/dnn/hidden3/BiasAdd_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'train/gradients/dnn/hidden3/BiasAdd_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'train/gradients/dnn/hidden3/MatMul_grad/MatMul' type=MatMul>,\n",
       " <tf.Operation 'train/gradients/dnn/hidden3/MatMul_grad/MatMul_1' type=MatMul>,\n",
       " <tf.Operation 'train/gradients/dnn/hidden3/MatMul_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'train/gradients/dnn/hidden3/MatMul_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'train/gradients/dnn/hidden3/MatMul_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'train/gradients/dnn/hidden2/Relu_grad/ReluGrad' type=ReluGrad>,\n",
       " <tf.Operation 'train/gradients/dnn/hidden2/BiasAdd_grad/BiasAddGrad' type=BiasAddGrad>,\n",
       " <tf.Operation 'train/gradients/dnn/hidden2/BiasAdd_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'train/gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'train/gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'train/gradients/dnn/hidden2/MatMul_grad/MatMul' type=MatMul>,\n",
       " <tf.Operation 'train/gradients/dnn/hidden2/MatMul_grad/MatMul_1' type=MatMul>,\n",
       " <tf.Operation 'train/gradients/dnn/hidden2/MatMul_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'train/gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'train/gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'train/gradients/dnn/hidden1/Relu_grad/ReluGrad' type=ReluGrad>,\n",
       " <tf.Operation 'train/gradients/dnn/hidden1/BiasAdd_grad/BiasAddGrad' type=BiasAddGrad>,\n",
       " <tf.Operation 'train/gradients/dnn/hidden1/BiasAdd_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'train/gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'train/gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'train/gradients/dnn/hidden1/MatMul_grad/MatMul' type=MatMul>,\n",
       " <tf.Operation 'train/gradients/dnn/hidden1/MatMul_grad/MatMul_1' type=MatMul>,\n",
       " <tf.Operation 'train/gradients/dnn/hidden1/MatMul_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'train/gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'train/gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'train/GradientDescent/learning_rate' type=Const>,\n",
       " <tf.Operation 'train/GradientDescent/update_hidden1/kernel/ApplyGradientDescent' type=ApplyGradientDescent>,\n",
       " <tf.Operation 'train/GradientDescent/update_hidden1/bias/ApplyGradientDescent' type=ApplyGradientDescent>,\n",
       " <tf.Operation 'train/GradientDescent/update_hidden2/kernel/ApplyGradientDescent' type=ApplyGradientDescent>,\n",
       " <tf.Operation 'train/GradientDescent/update_hidden2/bias/ApplyGradientDescent' type=ApplyGradientDescent>,\n",
       " <tf.Operation 'train/GradientDescent/update_hidden3/kernel/ApplyGradientDescent' type=ApplyGradientDescent>,\n",
       " <tf.Operation 'train/GradientDescent/update_hidden3/bias/ApplyGradientDescent' type=ApplyGradientDescent>,\n",
       " <tf.Operation 'train/GradientDescent/update_hidden4/kernel/ApplyGradientDescent' type=ApplyGradientDescent>,\n",
       " <tf.Operation 'train/GradientDescent/update_hidden4/bias/ApplyGradientDescent' type=ApplyGradientDescent>,\n",
       " <tf.Operation 'train/GradientDescent/update_outputs/kernel/ApplyGradientDescent' type=ApplyGradientDescent>,\n",
       " <tf.Operation 'train/GradientDescent/update_outputs/bias/ApplyGradientDescent' type=ApplyGradientDescent>,\n",
       " <tf.Operation 'train/GradientDescent' type=NoOp>,\n",
       " <tf.Operation 'save/Const' type=Const>,\n",
       " <tf.Operation 'save/SaveV2/tensor_names' type=Const>,\n",
       " <tf.Operation 'save/SaveV2/shape_and_slices' type=Const>,\n",
       " <tf.Operation 'save/SaveV2' type=SaveV2>,\n",
       " <tf.Operation 'save/control_dependency' type=Identity>,\n",
       " <tf.Operation 'save/RestoreV2/tensor_names' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2/shape_and_slices' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2' type=RestoreV2>,\n",
       " <tf.Operation 'save/Assign' type=Assign>,\n",
       " <tf.Operation 'save/Assign_1' type=Assign>,\n",
       " <tf.Operation 'save/Assign_2' type=Assign>,\n",
       " <tf.Operation 'save/Assign_3' type=Assign>,\n",
       " <tf.Operation 'save/Assign_4' type=Assign>,\n",
       " <tf.Operation 'save/Assign_5' type=Assign>,\n",
       " <tf.Operation 'save/Assign_6' type=Assign>,\n",
       " <tf.Operation 'save/Assign_7' type=Assign>,\n",
       " <tf.Operation 'save/Assign_8' type=Assign>,\n",
       " <tf.Operation 'save/Assign_9' type=Assign>,\n",
       " <tf.Operation 'save/restore_all' type=NoOp>,\n",
       " <tf.Operation 'init' type=NoOp>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "tf.train.import_meta_graph(\"tmp/layers_x4_mnist_model_final.ckpt.meta\")\n",
    "tf.get_default_graph().get_operations()\n",
    "# tf.get_default_graph().get_tensor_by_name(\"train/GradientDescent/update_outputs/bias/ApplyGradientDescent:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from tmp/layers_x4_mnist_model_final.ckpt\n",
      "Epoch: 0 Test loss: 0.10686793\n",
      "Epoch: 1 Test loss: 0.10657914\n",
      "Epoch: 2 Test loss: 0.10632399\n",
      "Epoch: 3 Test loss: 0.10609763\n",
      "Epoch: 4 Test loss: 0.10589534\n",
      "Epoch: 5 Test loss: 0.105713986\n",
      "Epoch: 6 Test loss: 0.10555039\n",
      "Epoch: 7 Test loss: 0.105402514\n",
      "Epoch: 8 Test loss: 0.10526825\n",
      "Epoch: 9 Test loss: 0.10514573\n",
      "Epoch: 10 Test loss: 0.10503374\n",
      "Epoch: 11 Test loss: 0.10493043\n",
      "Epoch: 12 Test loss: 0.104835495\n",
      "Epoch: 13 Test loss: 0.104747646\n",
      "Epoch: 14 Test loss: 0.10466616\n",
      "Epoch: 15 Test loss: 0.1045906\n",
      "Epoch: 16 Test loss: 0.1045198\n",
      "Epoch: 17 Test loss: 0.10445415\n",
      "Epoch: 18 Test loss: 0.10439314\n",
      "Epoch: 19 Test loss: 0.10433577\n",
      "Epoch: 20 Test loss: 0.10428163\n",
      "Epoch: 21 Test loss: 0.1042312\n",
      "Epoch: 22 Test loss: 0.10418347\n",
      "Epoch: 23 Test loss: 0.10413814\n",
      "Epoch: 24 Test loss: 0.10409582\n",
      "Epoch: 25 Test loss: 0.10405599\n",
      "Epoch: 26 Test loss: 0.104018286\n",
      "Epoch: 27 Test loss: 0.10398276\n",
      "Epoch: 28 Test loss: 0.103948794\n",
      "Epoch: 29 Test loss: 0.10391723\n",
      "Epoch: 30 Test loss: 0.103887\n",
      "Epoch: 31 Test loss: 0.10385847\n",
      "Epoch: 32 Test loss: 0.10383115\n",
      "Epoch: 33 Test loss: 0.10380525\n",
      "Epoch: 34 Test loss: 0.10378086\n",
      "Epoch: 35 Test loss: 0.103757724\n",
      "Epoch: 36 Test loss: 0.10373596\n",
      "Epoch: 37 Test loss: 0.10371508\n",
      "Epoch: 38 Test loss: 0.10369573\n",
      "Epoch: 39 Test loss: 0.10367657\n",
      "Epoch: 40 Test loss: 0.10365829\n",
      "Epoch: 41 Test loss: 0.10364136\n",
      "Epoch: 42 Test loss: 0.103625305\n",
      "Epoch: 43 Test loss: 0.103609726\n",
      "Epoch: 44 Test loss: 0.10359525\n",
      "Epoch: 45 Test loss: 0.103580676\n",
      "Epoch: 46 Test loss: 0.10356766\n",
      "Epoch: 47 Test loss: 0.10355487\n",
      "Epoch: 48 Test loss: 0.10354289\n",
      "Epoch: 49 Test loss: 0.10353102\n",
      "Epoch: 50 Test loss: 0.103520095\n",
      "Epoch: 51 Test loss: 0.10350979\n",
      "Epoch: 52 Test loss: 0.103499316\n",
      "Epoch: 53 Test loss: 0.10348955\n",
      "Epoch: 54 Test loss: 0.103480615\n",
      "Epoch: 55 Test loss: 0.10347117\n",
      "Epoch: 56 Test loss: 0.10346323\n",
      "Epoch: 57 Test loss: 0.103455484\n",
      "Epoch: 58 Test loss: 0.10344756\n",
      "Epoch: 59 Test loss: 0.10344043\n",
      "Epoch: 60 Test loss: 0.10343325\n",
      "Epoch: 61 Test loss: 0.10342659\n",
      "Epoch: 62 Test loss: 0.103419535\n",
      "Epoch: 63 Test loss: 0.10341292\n",
      "Epoch: 64 Test loss: 0.1034066\n",
      "Epoch: 65 Test loss: 0.103400685\n",
      "Epoch: 66 Test loss: 0.10339502\n",
      "Epoch: 67 Test loss: 0.10338962\n",
      "Epoch: 68 Test loss: 0.103384435\n",
      "Epoch: 69 Test loss: 0.103379495\n",
      "Epoch: 70 Test loss: 0.10337451\n",
      "Epoch: 71 Test loss: 0.10337031\n",
      "Epoch: 72 Test loss: 0.10336675\n",
      "Epoch: 73 Test loss: 0.10336231\n",
      "Epoch: 74 Test loss: 0.103358254\n",
      "Epoch: 75 Test loss: 0.10335462\n",
      "Epoch: 76 Test loss: 0.10335051\n",
      "Epoch: 77 Test loss: 0.10334703\n",
      "Epoch: 78 Test loss: 0.103343725\n",
      "Epoch: 79 Test loss: 0.10334026\n",
      "Epoch: 80 Test loss: 0.103336826\n",
      "Epoch: 81 Test loss: 0.10333391\n",
      "Epoch: 82 Test loss: 0.103330776\n",
      "Epoch: 83 Test loss: 0.10332764\n",
      "Epoch: 84 Test loss: 0.10332522\n",
      "Epoch: 85 Test loss: 0.103322715\n",
      "Epoch: 86 Test loss: 0.103320114\n",
      "Epoch: 87 Test loss: 0.10331766\n",
      "Epoch: 88 Test loss: 0.103315525\n",
      "Epoch: 89 Test loss: 0.103312954\n",
      "Epoch: 90 Test loss: 0.103310764\n",
      "Epoch: 91 Test loss: 0.10330869\n",
      "Epoch: 92 Test loss: 0.103306435\n",
      "Epoch: 93 Test loss: 0.10330435\n",
      "Epoch: 94 Test loss: 0.10330233\n",
      "Epoch: 95 Test loss: 0.10330077\n",
      "Epoch: 96 Test loss: 0.103298984\n",
      "Epoch: 97 Test loss: 0.10329703\n",
      "Epoch: 98 Test loss: 0.10329512\n",
      "Epoch: 99 Test loss: 0.10329369\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "\n",
    "tf.reset_default_graph()\n",
    "tf.train.import_meta_graph(\"tmp/layers_x4_mnist_model_final.ckpt.meta\")\n",
    "\n",
    "restore_saver = tf.train.Saver()\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"tmp/layers_x4_mnist_model_final.ckpt\")\n",
    "    \n",
    "    hidden2 = tf.get_default_graph().get_tensor_by_name(\"dnn/hidden2/Relu:0\")\n",
    "    X = tf.get_default_graph().get_tensor_by_name(\"X:0\")\n",
    "    y = tf.get_default_graph().get_tensor_by_name(\"y:0\")\n",
    "    training_op = tf.get_default_graph().get_tensor_by_name(\"train/GradientDescent/update_outputs/bias/ApplyGradientDescent:0\")\n",
    "    loss = tf.get_default_graph().get_tensor_by_name(\"loss/Mean:0\")\n",
    "    \n",
    "    h2_cache = sess.run([hidden2], feed_dict={X: X_train})\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        shuffled_idx = np.random.permutation(X_train.shape[0])\n",
    "        hidden2_batches = np.array_split(h2_cache[0][shuffled_idx], n_batches)\n",
    "        y_batches = np.array_split(y_train[shuffled_idx], n_batches)\n",
    "        for hidden2_batch, y_batch in zip(hidden2_batches, y_batches):\n",
    "            sess.run(training_op, feed_dict={hidden2:hidden2_batch, y:y_batch})\n",
    "            \n",
    "        loss_test = sess.run(loss, feed_dict={X:X_test, y:y_test})\n",
    "        print(\"Epoch:\", epoch, \"Test loss:\", loss_test)            \n",
    "            \n",
    "#     save_path = saver.save(sess, \"tmp/cached_mnist_model_final.ckpt\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Faster Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.9, use_nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate, momentum=0.9, decay=0.9, epsilon=1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning Rate Scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xx = np.linspace(0, 100, 101)\n",
    "eta_1 = 0.01 * np.power(10, -xx/10) \n",
    "eta_2 = 0.01 * np.power(1+xx/10, -1)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(xx, eta_1, label='Exponential')\n",
    "ax.plot(xx, eta_2, label='Power')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Learning Rate: 0.09997698 Global Step: 1 x: 0.8\n",
      "Epoch: 1 Learning Rate: 0.09995396 Global Step: 2 x: 2.159687\n",
      "Epoch: 2 Learning Rate: 0.09993095 Global Step: 3 x: 3.7510166\n",
      "Epoch: 3 Learning Rate: 0.09990794 Global Step: 4 x: 5.232646\n",
      "Epoch: 4 Learning Rate: 0.099884935 Global Step: 5 x: 6.319503\n",
      "Epoch: 5 Learning Rate: 0.09986194 Global Step: 6 x: 6.834082\n",
      "Epoch: 6 Learning Rate: 0.09983895 Global Step: 7 x: 6.731063\n",
      "Epoch: 7 Learning Rate: 0.09981596 Global Step: 8 x: 6.093034\n",
      "Epoch: 8 Learning Rate: 0.09979298 Global Step: 9 x: 5.101104\n",
      "Epoch: 9 Learning Rate: 0.09977 Global Step: 10 x: 3.9888074\n",
      "Epoch: 10 Learning Rate: 0.09974704 Global Step: 11 x: 2.9902046\n",
      "Epoch: 11 Learning Rate: 0.09972408 Global Step: 12 x: 2.293117\n",
      "Epoch: 12 Learning Rate: 0.09970111 Global Step: 13 x: 2.0063174\n",
      "Epoch: 13 Learning Rate: 0.09967816 Global Step: 14 x: 2.145802\n",
      "Epoch: 14 Learning Rate: 0.0996552 Global Step: 15 x: 2.6409552\n",
      "Epoch: 15 Learning Rate: 0.099632256 Global Step: 16 x: 3.3573623\n",
      "Epoch: 16 Learning Rate: 0.09960933 Global Step: 17 x: 4.130035\n",
      "Epoch: 17 Learning Rate: 0.09958639 Global Step: 18 x: 4.799375\n",
      "Epoch: 18 Learning Rate: 0.099563465 Global Step: 19 x: 5.242429\n",
      "Epoch: 19 Learning Rate: 0.09954055 Global Step: 20 x: 5.393684\n",
      "Epoch: 20 Learning Rate: 0.09951762 Global Step: 21 x: 5.2523265\n",
      "Epoch: 21 Learning Rate: 0.09949472 Global Step: 22 x: 4.875877\n",
      "Epoch: 22 Learning Rate: 0.0994718 Global Step: 23 x: 4.3628597\n",
      "Epoch: 23 Learning Rate: 0.099448904 Global Step: 24 x: 3.8290622\n",
      "Epoch: 24 Learning Rate: 0.09942601 Global Step: 25 x: 3.382754\n",
      "Epoch: 25 Learning Rate: 0.09940311 Global Step: 26 x: 3.10391\n",
      "Epoch: 26 Learning Rate: 0.099380225 Global Step: 27 x: 3.0311563\n",
      "Epoch: 27 Learning Rate: 0.09935735 Global Step: 28 x: 3.1582608\n",
      "Epoch: 28 Learning Rate: 0.09933447 Global Step: 29 x: 3.4398947\n",
      "Epoch: 29 Learning Rate: 0.0993116 Global Step: 30 x: 3.804582\n",
      "Epoch: 30 Learning Rate: 0.09928874 Global Step: 31 x: 4.17154\n",
      "Epoch: 31 Learning Rate: 0.09926587 Global Step: 32 x: 4.467662\n",
      "Epoch: 32 Learning Rate: 0.09924303 Global Step: 33 x: 4.6412644\n",
      "Epoch: 33 Learning Rate: 0.09922018 Global Step: 34 x: 4.670189\n",
      "Epoch: 34 Learning Rate: 0.09919733 Global Step: 35 x: 4.5632224\n",
      "Epoch: 35 Learning Rate: 0.09917449 Global Step: 36 x: 4.355234\n",
      "Epoch: 36 Learning Rate: 0.09915166 Global Step: 37 x: 4.0976276\n",
      "Epoch: 37 Learning Rate: 0.099128835 Global Step: 38 x: 3.8464754\n",
      "Epoch: 38 Learning Rate: 0.099106014 Global Step: 39 x: 3.6509278\n",
      "Epoch: 39 Learning Rate: 0.09908319 Global Step: 40 x: 3.5441658\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "initial_learning_rate = 0.1\n",
    "decay_steps = 10000\n",
    "decay_rate = 1/10\n",
    "global_step = tf.Variable(0, trainable=False, name=\"global_step\")\n",
    "learning_rate = tf.train.exponential_decay(initial_learning_rate, global_step, decay_steps, decay_rate)\n",
    "\n",
    "x = tf.Variable(0.0, dtype=tf.float32)\n",
    "loss = (x-4)**2\n",
    "\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate, momentum=0.9)\n",
    "training_op = optimizer.minimize(loss, global_step=global_step)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    \n",
    "    for epoch in range(40):\n",
    "        sess.run(training_op)\n",
    "        print(\"Epoch:\", epoch, \"Learning Rate:\", learning_rate.eval(), \"Global Step:\", global_step.eval(), \"x:\", x.eval())\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L1 & L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "\n",
    "tf.reset_default_graph()\n",
    "tf.train.import_meta_graph(\"tmp/layers_x4_mnist_model_final.ckpt.meta\")\n",
    "\n",
    "W1 = tf.get_default_graph().get_tensor_by_name(\"hidden1/kernel:0\")\n",
    "W2 = tf.get_default_graph().get_tensor_by_name(\"hidden2/kernel:0\")\n",
    "\n",
    "y = tf.placeholder(tf.int32, (None), \"y\")\n",
    "logits = tf.get_default_graph().get_tensor_by_name(\"outputs/kernel:0\")\n",
    "\n",
    "scale = 0.001\n",
    "\n",
    "restore_saver = tf.train.Saver()\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    base_loss = tf.reduce_mean(xentropy, name=\"avg_xentropy\")\n",
    "    reg_losses = tf.reduce_sum(tf.abs(W1)) + tf.reduce_sum(tf.abs(W2))\n",
    "    loss = tf.add(base_loss, scale * reg_losses, name=\"loss\") # add to overall loss!   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, (None, n_inputs), \"X\")\n",
    "y = tf.placeholder(tf.int32, (None), \"y\")\n",
    "\n",
    "my_dense_layer = partial(\n",
    "    tf.layers.dense,\n",
    "    activation=tf.nn.relu,\n",
    "    kernel_regularizer=tf.contrib.layers.l1_regularizer(scale))\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = my_dense_layer(X, n_hidden1, name=\"hidden1\")\n",
    "    hidden2 = my_dense_layer(hidden1, n_hidden2, name=\"hidden2\")\n",
    "    logits = my_dense_layer(hidden2, n_outputs, activation=None, name=\"outputs\")\n",
    "    \n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    base_loss = tf.reduce_mean(xentropy, name=\"avg_xentropy\")\n",
    "    \n",
    "    reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "    loss = tf.add_n([base_loss] + reg_losses, name=\"loss\") # add to overall loss!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "dropout_rate = 0.5\n",
    "X = tf.placeholder(tf.float32, (None, n_inputs), \"X\")\n",
    "X_drop = tf.layers.dropout(X, dropout_rate, training=training)\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X_drop, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "    hidden1_drop = tf.layers.dropout(hidden1, dropout_rate, training=training)\n",
    "    hidden2 = tf.layers.dense(hidden1_drop, n_hidden2, activation=tf.nn.relu, name=\"hidden2\")\n",
    "    hidden2_drop = tf.layers.dropout(hidden2, dropout_rate, training=training)\n",
    "    logits = tf.layers.dense(hidden2_drop, n_outputs, name=\"outputs\")    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
